{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"pubmed_qa\", \"pqa_labeled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syllable_tokenizer = AutoTokenizer.from_pretrained(\"vinai/bartpho-syllable\")\n",
    "bartpho_syllable = AutoModel.from_pretrained(\"vinai/bartpho-syllable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syllable_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bartpho_syllable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TXT = dataset[\"train\"][0]['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = syllable_tokenizer(TXT, return_tensors='pt')['input_ids']\n",
    "features = bartpho_syllable(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenizer = AutoTokenizer.from_pretrained(\"vinai/bartpho-word\")\n",
    "bartpho_word = AutoModel.from_pretrained(\"vinai/bartpho-word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TXT = dataset[\"train\"][0]['question']\n",
    "input_ids = word_tokenizer(TXT, return_tensors='pt')['input_ids']\n",
    "features = bartpho_word(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create embeddings\n",
    "def get_embedding(text):\n",
    "    inputs = word_tokenizer(text, return_tensors=\"pt\")['input_ids']\n",
    "    with torch.no_grad():\n",
    "        outputs = bartpho_word(inputs)\n",
    "    # Use the last hidden state of the first token as the sentence embedding\n",
    "    embedding = outputs.last_hidden_state[:, 0, :]\n",
    "    return embedding.squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = get_embedding(TXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from dotenv import load_dotenv\n",
    "from qdrant_client.models import Distance, VectorParams\n",
    "from qdrant_client.models import PointStruct\n",
    "from qdrant_client.models import Filter, FieldCondition, MatchValue\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "qdrant_url = os.getenv('QDRANT_URL')\n",
    "\n",
    "client = QdrantClient(url=qdrant_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "for i in  tqdm.tqdm(range(len(dataset[\"train\"]))):\n",
    "    vector = get_embedding(dataset[\"train\"][0]['long_answer'])\n",
    "    embeddings.append(vector)\n",
    "\n",
    "vector = [\n",
    "    list(map(float, vector))\n",
    "    for vector in embeddings\n",
    "]\n",
    "\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vector[0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [entry[\"pubid\"] for entry in dataset[\"train\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.http import models as rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.create_collection(\n",
    "    collection_name=\"pubmed_qa\",\n",
    "    vectors_config=VectorParams(size=1024, distance=Distance.DOT),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.upsert(\n",
    "    collection_name=\"pubmed_qa\", \n",
    "    points=rest.Batch(\n",
    "        ids=ids,\n",
    "        vectors=vector,\n",
    "        payloads=list(dataset[\"train\"]),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_response = []\n",
    "for i in  tqdm.tqdm(range(len(dataset[\"train\"]))):\n",
    "    vector = get_embedding(dataset[\"train\"][0]['question'])\n",
    "    question_response.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip(question_response, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the position at which Qdrant provided the expected answer for each question. \n",
    "# That allows to calculate accuracy@k for different values of k.\n",
    "k_max = 10\n",
    "answer_positions = []\n",
    "for embedding, pubid in tqdm.tqdm(zip(question_response, ids)):\n",
    "    response = client.search(\n",
    "        collection_name=\"pubmed_qa\",\n",
    "        query_vector=embedding,\n",
    "        limit=k_max,\n",
    "    )\n",
    "\n",
    "    answer_ids = [record.id for record in response]\n",
    "    if pubid in answer_ids:\n",
    "        answer_positions.append(answer_ids.index(pubid))\n",
    "    else:\n",
    "        answer_positions.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for i in answer_positions:\n",
    "    if i != -1:\n",
    "        c += 1\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bert-large-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-cased')\n",
    "model = BertModel.from_pretrained(\"bert-large-cased\")\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create embeddings\n",
    "def get_embedding_common(text, tokenizer, model):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")['input_ids']\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "    # Use the last hidden state of the first token as the sentence embedding\n",
    "    embedding = outputs.last_hidden_state[:, 0, :]\n",
    "    return embedding.squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_embeddings = []\n",
    "for i in  tqdm.tqdm(range(len(dataset[\"train\"]))):\n",
    "    vector = get_embedding_common(dataset[\"train\"][0]['long_answer'], tokenizer, model)\n",
    "    answer_embeddings.append(vector)\n",
    "\n",
    "question_response = []\n",
    "for i in  tqdm.tqdm(range(len(dataset[\"train\"]))):\n",
    "    ebd_vt = get_embedding_common(dataset[\"train\"][0]['question'], tokenizer, model)\n",
    "    question_response.append(ebd_vt)\n",
    "\n",
    "vector = [\n",
    "    list(map(float, vector))\n",
    "    for vector in embeddings\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=\"pubmed_qa_bert_cosin\",\n",
    "    vectors_config=VectorParams(size=1024, distance=Distance.COSINE),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.upsert(\n",
    "    collection_name=\"pubmed_qa_bert_cosin\", \n",
    "    points=rest.Batch(\n",
    "        ids=ids,\n",
    "        vectors=vector,\n",
    "        payloads=list(dataset[\"train\"]),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the position at which Qdrant provided the expected answer for each question. \n",
    "# That allows to calculate accuracy@k for different values of k.\n",
    "k_max = 10\n",
    "answer_positions = []\n",
    "for embedding, pubid in tqdm.tqdm(zip(question_response, ids)):\n",
    "    response = client.search(\n",
    "        collection_name=\"pubmed_qa_bert_cosin\",\n",
    "        query_vector=embedding,\n",
    "        limit=k_max,\n",
    "    )\n",
    "\n",
    "    answer_ids = [record.id for record in response]\n",
    "    if pubid in answer_ids:\n",
    "        answer_positions.append(answer_ids.index(pubid))\n",
    "    else:\n",
    "        answer_positions.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepared answer positions are being used to calculate different values of accuracy@k\n",
    "for k in range(1, k_max + 1):\n",
    "    correct_answers = len(\n",
    "        list(\n",
    "            filter(lambda x: 0 <= x < k, answer_positions)\n",
    "        )\n",
    "    )\n",
    "    print(f\"accuracy@{k} =\", correct_answers / len(dataset[\"train\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cohere==4.21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "\n",
    "COHERE_API_KEY = \"KqApPE9kQ9TSKjc8OkD0X9W2YEJlCkQBmg1Xb1tv\"\n",
    "cohere_client = cohere.Client(COHERE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unknown field: parameter compress is not a valid field\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096\n"
     ]
    }
   ],
   "source": [
    "# Generating the embeddings with Cohere client library\n",
    "embeddings = cohere_client.embed(\n",
    "    texts=[\"A test sentence\"],\n",
    "    model=\"large\",\n",
    ")\n",
    "vector_size = len(embeddings.embeddings[0])\n",
    "print(vector_size) # output: 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unknown field: parameter compress is not a valid field\n",
      "unknown field: parameter compress is not a valid field\n",
      "unknown field: parameter compress is not a valid field\n",
      "unknown field: parameter compress is not a valid field\n",
      "unknown field: parameter compress is not a valid field\n",
      "unknown field: parameter compress is not a valid field\n",
      "unknown field: parameter compress is not a valid field\n",
      "unknown field: parameter compress is not a valid field\n",
      "unknown field: parameter compress is not a valid field\n",
      "unknown field: parameter compress is not a valid field\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unknown field: parameter compress is not a valid field\n",
      "unknown field: parameter compress is not a valid field\n"
     ]
    }
   ],
   "source": [
    "answer_response = cohere_client.embed(\n",
    "    texts=dataset[\"train\"][\"long_answer\"],\n",
    "    model=\"large\",\n",
    ")\n",
    "vectors = [\n",
    "    # Conversion to float is required for Qdrant\n",
    "    list(map(float, vector)) \n",
    "    for vector in answer_response.embeddings\n",
    "]\n",
    "ids = [entry[\"pubid\"] for entry in dataset[\"train\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.create_collection(\n",
    "    collection_name=\"pubmed_qa_cohere_4096\",\n",
    "    vectors_config=VectorParams(size=4096, distance=Distance.COSINE),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.upsert(\n",
    "    collection_name=\"pubmed_qa_cohere_4096\", \n",
    "    points=rest.Batch(\n",
    "        ids=ids[0:100],\n",
    "        vectors=vectors[0:100],\n",
    "        payloads=list(dataset[\"train\"])[:100],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unknown field: parameter compress is not a valid field\n",
      "unknown field: parameter compress is not a valid field\n",
      "unknown field: parameter compress is not a valid field\n",
      "unknown field: parameter compress is not a valid field\n",
      "unknown field: parameter compress is not a valid field\n",
      "unknown field: parameter compress is not a valid field\n",
      "unknown field: parameter compress is not a valid field\n",
      "unknown field: parameter compress is not a valid field\n",
      "unknown field: parameter compress is not a valid field\n",
      "unknown field: parameter compress is not a valid field\n"
     ]
    }
   ],
   "source": [
    "question_response = cohere_client.embed(\n",
    "    texts=dataset[\"train\"][\"question\"],\n",
    "    model=\"large\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cohere.responses.embeddings.Embeddings"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(question_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(question_response.embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 237.01it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "# Finding the position at which Qdrant provided the expected answer for each question. \n",
    "# That allows to calculate accuracy@k for different values of k.\n",
    "k_max = 10\n",
    "answer_positions = []\n",
    "for embedding, pubid in tqdm.tqdm(zip(question_response.embeddings[:100], ids)):\n",
    "    response = client.search(\n",
    "        collection_name=\"pubmed_qa_cohere_4096\",\n",
    "        query_vector=embedding,\n",
    "        limit=k_max,\n",
    "    )\n",
    "\n",
    "    answer_ids = [record.id for record in response]\n",
    "    if pubid in answer_ids:\n",
    "        answer_positions.append(answer_ids.index(pubid))\n",
    "    else:\n",
    "        answer_positions.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy@1 = 0.094\n",
      "accuracy@2 = 0.095\n",
      "accuracy@3 = 0.095\n",
      "accuracy@4 = 0.097\n",
      "accuracy@5 = 0.098\n",
      "accuracy@6 = 0.098\n",
      "accuracy@7 = 0.098\n",
      "accuracy@8 = 0.099\n",
      "accuracy@9 = 0.099\n",
      "accuracy@10 = 0.099\n"
     ]
    }
   ],
   "source": [
    "# Prepared answer positions are being used to calculate different values of accuracy@k\n",
    "for k in range(1, k_max + 1):\n",
    "    correct_answers = len(\n",
    "        list(\n",
    "            filter(lambda x: 0 <= x < k, answer_positions)\n",
    "        )\n",
    "    )\n",
    "    print(f\"accuracy@{k} =\", correct_answers / len(dataset[\"train\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
